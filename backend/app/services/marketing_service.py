"""
Marketing Service - å°çº¢ä¹¦é£æ ¼è¥é”€æ–‡æ¡ˆç”ŸæˆæœåŠ¡

è´Ÿè´£ä¸º Episode ç”Ÿæˆå°çº¢ä¹¦é£æ ¼çš„è¥é”€æ–‡æ¡ˆï¼ŒåŒ…æ‹¬ï¼š
1. é‡‘å¥æå–
2. æ ‡é¢˜ç”Ÿæˆ
3. è¯é¢˜æ ‡ç­¾ç”Ÿæˆ
4. å®Œæ•´æ–‡æ¡ˆç”Ÿæˆ
5. æ–‡æ¡ˆæŒä¹…åŒ–

Migrated to use StructuredLLM with Pydantic validation and retry logic.
"""
import json
import re
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor, TimeoutError as FutureTimeoutError

from loguru import logger
from sqlalchemy.orm import Session
from langchain_core.messages import SystemMessage, HumanMessage

from app.models import Episode, MarketingPost, TranscriptCue, AudioSegment, Chapter, Translation
from app.config import (
    get_marketing_llm_config,
    AI_QUERY_TIMEOUT,
    MOONSHOT_API_KEY, MOONSHOT_BASE_URL, MOONSHOT_MODEL,
    ZHIPU_API_KEY, ZHIPU_BASE_URL, ZHIPU_MODEL,
    GEMINI_API_KEY, GEMINI_MODEL
)
from app.services.ai.structured_llm import StructuredLLM
from app.services.ai.schemas.marketing_schema import MultiAngleMarketingResponse, MarketingAngle
from app.services.ai.retry import ai_retry


@dataclass
class MarketingCopy:
    """è¥é”€æ–‡æ¡ˆç»“æœ"""
    title: str
    content: str
    hashtags: List[str]
    key_quotes: List[str]
    metadata: Dict[str, Any] = field(default_factory=dict)


class MarketingService:
    """
    è¥é”€æ–‡æ¡ˆç”ŸæˆæœåŠ¡ (å°çº¢ä¹¦é£æ ¼)

    è´Ÿè´£ï¼š
    1. ä¸º Episode ç”Ÿæˆå°çº¢ä¹¦é£æ ¼è¥é”€æ–‡æ¡ˆ
    2. æå–æ ¸å¿ƒè§‚ç‚¹å’Œé‡‘å¥
    3. ç”Ÿæˆå¸å¼•äººçš„æ ‡é¢˜å’Œè¯é¢˜æ ‡ç­¾

    Uses StructuredLLM with Pydantic validation for reliable structured output.
    """

    def __init__(
        self,
        db: Session,
        provider: Optional[str] = None,
        api_key: Optional[str] = None
    ):
        """
        åˆå§‹åŒ–æœåŠ¡

        Args:
            db: æ•°æ®åº“ä¼šè¯
            provider: AI provider name (optional, defaults to config MARKETING_LLM_PROVIDER)
            api_key: API key (optional, defaults to config)
        """
        self.db = db

        # è·å–è¥é”€æœåŠ¡ä¸“ç”¨çš„ LLM é…ç½®
        if provider is None:
            provider = get_marketing_llm_config()["provider"] if hasattr(get_marketing_llm_config(), 'get') else "zhipu"

        self.provider = provider

        # Initialize StructuredLLM
        if api_key is None:
            llm_config = get_marketing_llm_config()
            api_key = llm_config["api_key"]

        try:
            self.structured_llm = StructuredLLM(
                provider=provider,
                model=llm_config["model"],
                api_key=api_key,
                base_url=llm_config["base_url"]
            )
            logger.info(f"MarketingService: Initialized {provider} StructuredLLM")
        except Exception as e:
            logger.error(f"Failed to initialize StructuredLLM: {e}")
            self.structured_llm = None

        # å…¼å®¹æ—§é…ç½®
        self._llm_config = get_marketing_llm_config()

        # OpenAI client for non-structured outputs (titles, hashtags)
        try:
            from openai import OpenAI
            self._openai_client = OpenAI(
                api_key=api_key,
                base_url=llm_config["base_url"]
            )
        except Exception as e:
            logger.error(f"Failed to initialize OpenAI client: {e}")
            self._openai_client = None

        # ä¿ç•™æ—§çš„é…ç½®ç”¨äºå…¼å®¹
        self._llm_config = get_marketing_llm_config()

    # ========================================================================
    # é‡‘å¥æå–
    # ========================================================================

    def extract_key_quotes(
        self,
        episode_id: int,
        max_quotes: int = 5
    ) -> List[str]:
        """
        æå–å…³é”®é‡‘å¥

        Args:
            episode_id: Episode ID
            max_quotes: æœ€å¤šæå–é‡‘å¥æ•°é‡

        Returns:
            List[str]: é‡‘å¥åˆ—è¡¨

        Raises:
            ValueError: Episode ä¸å­˜åœ¨
        """
        logger.debug(f"æå–é‡‘å¥: episode_id={episode_id}, max_quotes={max_quotes}")

        # è·å– Episode
        episode = self.db.query(Episode).filter(Episode.id == episode_id).first()
        if not episode:
            raise ValueError(f"Episode not found: id={episode_id}")

        quotes = []

        # ä» ai_summary ä¸­æå–å¥å­
        if episode.ai_summary:
            # æŒ‰å¥å·ã€é—®å·ã€æ„Ÿå¹å·åˆ†å‰²
            sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]', episode.ai_summary)
            # è¿‡æ»¤ç©ºå¥å­ï¼Œä½†å…è®¸è¾ƒçŸ­çš„å¥å­ï¼ˆé™ä½é˜ˆå€¼ä»10åˆ°2ï¼‰
            sentences = [s.strip() for s in sentences if len(s.strip()) > 2]
            quotes.extend(sentences[:max_quotes])

        # å¦‚æœæ‘˜è¦ä¸­çš„å¥å­ä¸å¤Ÿï¼Œä» TranscriptCue ä¸­æå–
        if len(quotes) < max_quotes:
            remaining = max_quotes - len(quotes)
            cues = self.db.query(TranscriptCue).join(
                AudioSegment, TranscriptCue.segment_id == AudioSegment.id
            ).filter(
                AudioSegment.episode_id == episode_id
            ).order_by(TranscriptCue.start_time).limit(remaining * 2).all()

            # é€‰æ‹©è¾ƒé•¿çš„å­—å¹•ä½œä¸ºé‡‘å¥
            for cue in cues:
                if len(cue.text) > 5 and len(quotes) < max_quotes:
                    quotes.append(cue.text)

        return quotes[:max_quotes]

    # ========================================================================
    # æ ‡é¢˜ç”Ÿæˆ
    # ========================================================================

    def generate_titles(
        self,
        episode_id: int,
        count: int = 5
    ) -> List[str]:
        """
        ç”Ÿæˆå¸å¼•äººçš„æ ‡é¢˜

        Args:
            episode_id: Episode ID
            count: ç”Ÿæˆæ ‡é¢˜æ•°é‡

        Returns:
            List[str]: æ ‡é¢˜åˆ—è¡¨

        Raises:
            ValueError: Episode ä¸å­˜åœ¨
        """
        logger.debug(f"ç”Ÿæˆæ ‡é¢˜: episode_id={episode_id}, count={count}")

        # è·å– Episode
        episode = self.db.query(Episode).filter(Episode.id == episode_id).first()
        if not episode:
            raise ValueError(f"Episode not found: id={episode_id}")

        # è°ƒç”¨ LLM ç”Ÿæˆæ ‡é¢˜
        return self._call_llm_for_titles(episode, count)

    def _call_llm_for_titles(self, episode: Episode, count: int) -> List[str]:
        """
        è°ƒç”¨ LLM ç”Ÿæˆæ ‡é¢˜

        Args:
            episode: Episode å¯¹è±¡
            count: ç”Ÿæˆæ•°é‡

        Returns:
            List[str]: æ ‡é¢˜åˆ—è¡¨
        """
        if self._openai_client:
            try:
                system_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å°çº¢ä¹¦è¥é”€æ–‡æ¡ˆä¸“å®¶ã€‚
è¯·æ ¹æ®æ’­å®¢å†…å®¹ç”Ÿæˆå¸å¼•äººçš„å°çº¢ä¹¦æ ‡é¢˜ã€‚

è¦æ±‚ï¼š
1. ç”Ÿæˆ {count} ä¸ªä¸åŒçš„æ ‡é¢˜
2. æ¯ä¸ªæ ‡é¢˜è¦åŒ…å« emoji è¡¨æƒ…
3. æ ‡é¢˜è¦å¸å¼•çœ¼çƒï¼Œç¬¦åˆå°çº¢ä¹¦é£æ ¼
4. æ ‡é¢˜é•¿åº¦æ§åˆ¶åœ¨ 30 å­—ä»¥å†…
5. ç›´æ¥è¿”å›æ ‡é¢˜åˆ—è¡¨ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹

è¾“å‡ºæ ¼å¼ï¼š
æ ‡é¢˜1
æ ‡é¢˜2
æ ‡é¢˜3
...""".format(count=count)

                user_prompt = f"""æ’­å®¢æ ‡é¢˜ï¼š{episode.title}
æ’­å®¢æ‘˜è¦ï¼š{episode.ai_summary or 'æš‚æ— æ‘˜è¦'}

è¯·æ ¹æ®ä»¥ä¸Šå†…å®¹ç”Ÿæˆ {count} ä¸ªå°çº¢ä¹¦æ ‡é¢˜ï¼š"""

                executor = ThreadPoolExecutor(max_workers=1)

                def call_ai():
                    completion = self._openai_client.chat.completions.create(
                        model=self._llm_config["model"],
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        temperature=0.8,
                    )
                    return completion.choices[0].message.content

                try:
                    future = executor.submit(call_ai)
                    response_text = future.result(timeout=AI_QUERY_TIMEOUT)
                    executor.shutdown(wait=False)

                    # è§£æè¿”å›çš„æ ‡é¢˜åˆ—è¡¨
                    titles = [line.strip() for line in response_text.split('\n') if line.strip()]
                    return titles[:count]

                except FutureTimeoutError:
                    logger.error("AI æ ‡é¢˜ç”Ÿæˆè¶…æ—¶ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
                    executor.shutdown(wait=False)
                except Exception as e:
                    logger.error(f"AI æ ‡é¢˜ç”Ÿæˆå¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")

            except Exception as e:
                logger.error(f"AI æ ‡é¢˜ç”Ÿæˆåˆå§‹åŒ–å¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")

        # å¤‡ç”¨æ–¹æ¡ˆï¼šè¿”å›æ¨¡æ‹Ÿæ•°æ®
        titles = [
            f"ğŸ¯ {episode.title}",
            f"ğŸ’¡ å…³äº{episode.title}çš„æ€è€ƒ",
            f"ğŸ”¥ {episode.title}æ·±åº¦è§£æ",
            f"âœ¨ {episode.title}åˆ†äº«",
            f"ğŸ“š {episode.title}å¹²è´§"
        ]
        return titles[:count]

    # ========================================================================
    # è¯é¢˜æ ‡ç­¾ç”Ÿæˆ
    # ========================================================================

    def generate_hashtags(
        self,
        episode_id: int,
        max_tags: int = 10
    ) -> List[str]:
        """
        ç”Ÿæˆè¯é¢˜æ ‡ç­¾

        Args:
            episode_id: Episode ID
            max_tags: æœ€å¤šç”Ÿæˆæ ‡ç­¾æ•°é‡

        Returns:
            List[str]: è¯é¢˜æ ‡ç­¾åˆ—è¡¨ï¼ˆå¸¦ # å‰ç¼€ï¼‰

        Raises:
            ValueError: Episode ä¸å­˜åœ¨
        """
        logger.debug(f"ç”Ÿæˆæ ‡ç­¾: episode_id={episode_id}, max_tags={max_tags}")

        # è·å– Episode
        episode = self.db.query(Episode).filter(Episode.id == episode_id).first()
        if not episode:
            raise ValueError(f"Episode not found: id={episode_id}")

        # è°ƒç”¨ LLM ç”Ÿæˆæ ‡ç­¾
        return self._call_llm_for_hashtags(episode, max_tags)

    def _call_llm_for_hashtags(self, episode: Episode, max_tags: int) -> List[str]:
        """
        è°ƒç”¨ LLM ç”Ÿæˆæ ‡ç­¾

        Args:
            episode: Episode å¯¹è±¡
            max_tags: æœ€å¤šç”Ÿæˆæ•°é‡

        Returns:
            List[str]: æ ‡ç­¾åˆ—è¡¨
        """
        if self._openai_client:
            try:
                system_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å°çº¢ä¹¦è¥é”€æ–‡æ¡ˆä¸“å®¶ã€‚
è¯·æ ¹æ®æ’­å®¢å†…å®¹ç”Ÿæˆç›¸å…³çš„è¯é¢˜æ ‡ç­¾ã€‚

è¦æ±‚ï¼š
1. ç”Ÿæˆ {max_tags} ä¸ªç›¸å…³æ ‡ç­¾
2. æ¯ä¸ªæ ‡ç­¾å¿…é¡»ä»¥ # å¼€å¤´
3. æ ‡ç­¾è¦ä¸å†…å®¹ç›¸å…³ï¼Œç¬¦åˆå°çº¢ä¹¦çƒ­é—¨è¯é¢˜
4. æ ‡ç­¾ç”¨ç©ºæ ¼åˆ†éš”ï¼Œä¸è¦æœ‰æ¢è¡Œ
5. ä¸è¦æœ‰å…¶ä»–è§£é‡Šæ–‡å­—

è¾“å‡ºæ ¼å¼ï¼š
#æ ‡ç­¾1 #æ ‡ç­¾2 #æ ‡ç­¾3 #æ ‡ç­¾4 #æ ‡ç­¾5 ..."""

                user_prompt = f"""æ’­å®¢æ ‡é¢˜ï¼š{episode.title}
æ’­å®¢æ‘˜è¦ï¼š{episode.ai_summary or 'æš‚æ— æ‘˜è¦'}

è¯·æ ¹æ®ä»¥ä¸Šå†…å®¹ç”Ÿæˆ {max_tags} ä¸ªç›¸å…³æ ‡ç­¾ï¼š"""

                executor = ThreadPoolExecutor(max_workers=1)

                def call_ai():
                    completion = self._openai_client.chat.completions.create(
                        model=self._llm_config["model"],
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        temperature=0.7,
                    )
                    return completion.choices[0].message.content

                try:
                    future = executor.submit(call_ai)
                    response_text = future.result(timeout=AI_QUERY_TIMEOUT)
                    executor.shutdown(wait=False)

                    # è§£æè¿”å›çš„æ ‡ç­¾åˆ—è¡¨
                    hashtags = re.findall(r'#[\w\u4e00-\u9fff]+', response_text)
                    return hashtags[:max_tags]

                except FutureTimeoutError:
                    logger.error("AI æ ‡ç­¾ç”Ÿæˆè¶…æ—¶ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
                    executor.shutdown(wait=False)
                except Exception as e:
                    logger.error(f"AI æ ‡ç­¾ç”Ÿæˆå¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")

            except Exception as e:
                logger.error(f"AI æ ‡ç­¾ç”Ÿæˆåˆå§‹åŒ–å¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")

        # å¤‡ç”¨æ–¹æ¡ˆï¼šè¿”å›é€šç”¨æ ‡ç­¾
        tags = [
            "#å­¦ä¹ å¹²è´§",
            "#çŸ¥è¯†åˆ†äº«",
            "#æ·±åº¦æ€è€ƒ",
            "#å†…å®¹è¾“å‡º",
            "#ä¸ªäººæˆé•¿",
            "#æŠ€èƒ½æå‡",
            "#è®¤çŸ¥å‡çº§",
            "#å­¦ä¹ æ–¹æ³•",
            "#å¹²è´§æ”¶è—",
            "#çŸ¥è¯†ç®¡ç†"
        ]
        return tags[:max_tags]

    # ========================================================================
    # å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆ
    # ========================================================================

    def _get_full_transcripts(self, episode_id: int, language_code: str = "zh") -> str:
        """
        è·å– Episode çš„å®Œæ•´å­—å¹•å†…å®¹ï¼ˆè‹±æ–‡+ä¸­æ–‡ç¿»è¯‘ï¼‰

        Args:
            episode_id: Episode ID
            language_code: ç¿»è¯‘è¯­è¨€ä»£ç 

        Returns:
            str: å®Œæ•´å­—å¹•æ–‡æœ¬
        """
        # è·å–æ‰€æœ‰å­—å¹•ï¼ŒæŒ‰æ—¶é—´æ’åº
        cues = self.db.query(TranscriptCue).join(
            AudioSegment, TranscriptCue.segment_id == AudioSegment.id
        ).filter(
            AudioSegment.episode_id == episode_id
        ).order_by(TranscriptCue.start_time).all()

        if not cues:
            return "æš‚æ— å­—å¹•å†…å®¹"

        # æ„å»ºå­—å¹•æ–‡æœ¬
        transcripts_parts = []
        for cue in cues:
            # è·å–ç¿»è¯‘
            translation = cue.get_translation(language_code)
            translation_text = translation if translation else ""

            # æ ¼å¼åŒ–ï¼š[æ—¶é—´] è¯´è¯äºº: è‹±æ–‡å†…å®¹ -> ä¸­æ–‡ç¿»è¯‘
            part = f"[{cue.start_time:.1f}s] {cue.speaker}: {cue.text}"
            if translation_text:
                part += f"\nç¿»è¯‘: {translation_text}"
            transcripts_parts.append(part)

        return "\n\n".join(transcripts_parts)

    def generate_xiaohongshu_copy(
        self,
        episode_id: int,
        language: str = "zh"
    ) -> MarketingCopy:
        """
        ç”Ÿæˆå°çº¢ä¹¦é£æ ¼æ–‡æ¡ˆï¼ˆå•ç‰ˆæœ¬ï¼Œå·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨ generate_xiaohongshu_copy_multi_angleï¼‰

        Args:
            episode_id: Episode ID
            language: è¯­è¨€ä»£ç 

        Returns:
            MarketingCopy: ç”Ÿæˆçš„æ–‡æ¡ˆå¯¹è±¡

        Raises:
            ValueError: Episode ä¸å­˜åœ¨æˆ–æ•°æ®ä¸å®Œæ•´
        """
        logger.info(f"ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆ: episode_id={episode_id}")

        # è·å– Episode
        episode = self.db.query(Episode).filter(Episode.id == episode_id).first()
        if not episode:
            raise ValueError(f"Episode not found: id={episode_id}")

        # 1. æå–é‡‘å¥
        key_quotes = self.extract_key_quotes(episode_id, max_quotes=3)

        # 2. ç”Ÿæˆæ ‡é¢˜
        titles = self.generate_titles(episode_id, count=1)
        title = titles[0] if titles else episode.title

        # 3. ç”Ÿæˆæ ‡ç­¾
        hashtags = self.generate_hashtags(episode_id, max_tags=5)

        # 4. ç”Ÿæˆæ­£æ–‡å†…å®¹
        content = self._call_llm_for_xiaohongshu_content(episode, key_quotes)

        return MarketingCopy(
            title=title,
            content=content,
            hashtags=hashtags,
            key_quotes=key_quotes,
            metadata={
                "episode_id": episode_id,
                "language": language,
                "platform": "xiaohongshu"
            }
        )

    def generate_xiaohongshu_copy_multi_angle(
        self,
        episode_id: int,
        language: str = "zh"
    ) -> List[MarketingCopy]:
        """
        ç”Ÿæˆå°çº¢ä¹¦é£æ ¼æ–‡æ¡ˆï¼ˆå¤šç‰ˆæœ¬ - 3ä¸ªä¸åŒè§’åº¦ï¼‰

        LLM è‡ªå·±å†³å®šè§’åº¦ï¼Œä¸€æ¬¡è°ƒç”¨ç”Ÿæˆ3ä¸ªç‰ˆæœ¬ï¼Œå¹¶ä¼ é€’å®Œæ•´å­—å¹•å†…å®¹

        Args:
            episode_id: Episode ID
            language: è¯­è¨€ä»£ç 

        Returns:
            List[MarketingCopy]: 3ä¸ªä¸åŒè§’åº¦çš„æ–‡æ¡ˆå¯¹è±¡

        Raises:
            ValueError: Episode ä¸å­˜åœ¨æˆ–æ•°æ®ä¸å®Œæ•´
        """
        logger.info(f"ç”Ÿæˆå°çº¢ä¹¦å¤šè§’åº¦æ–‡æ¡ˆ: episode_id={episode_id}")

        # è·å– Episode
        episode = self.db.query(Episode).filter(Episode.id == episode_id).first()
        if not episode:
            raise ValueError(f"Episode not found: id={episode_id}")

        # 1. æå–é‡‘å¥
        key_quotes = self.extract_key_quotes(episode_id, max_quotes=3)

        # 2. è·å–å®Œæ•´å­—å¹•å†…å®¹
        transcripts_text = self._get_full_transcripts(episode_id, language)

        # 3. ä¸€æ¬¡è°ƒç”¨ç”Ÿæˆ3ä¸ªè§’åº¦çš„æ–‡æ¡ˆ
        angle_copies = self._call_llm_for_multi_angle_content(
            episode, key_quotes, transcripts_text
        )

        return angle_copies

    @ai_retry(max_retries=2, initial_delay=1.0, retry_on=(ValueError, Exception))
    def _call_llm_for_multi_angle_content(
        self,
        episode: Episode,
        key_quotes: List[str],
        transcripts_text: str
    ) -> List[MarketingCopy]:
        """
        è°ƒç”¨ LLM ç”Ÿæˆ3ä¸ªä¸åŒè§’åº¦çš„å°çº¢ä¹¦é£æ ¼æ–‡æ¡ˆï¼ˆä½¿ç”¨ StructuredLLMï¼‰

        Args:
            episode: Episode å¯¹è±¡
            key_quotes: é‡‘å¥åˆ—è¡¨
            transcripts_text: å®Œæ•´å­—å¹•å†…å®¹

        Returns:
            List[MarketingCopy]: 3ä¸ªä¸åŒè§’åº¦çš„æ–‡æ¡ˆå¯¹è±¡

        Raises:
            ValueError: StructuredLLM åˆå§‹åŒ–å¤±è´¥æˆ–éªŒè¯å¤±è´¥ï¼ˆè§¦å‘ @ai_retryï¼‰
            Exception: å…¶ä»–å¼‚å¸¸ï¼ˆè§¦å‘ @ai_retryï¼‰
        """
        if not self.structured_llm:
            logger.error("StructuredLLM æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
            return self._generate_fallback_multi_angle_copy(episode, key_quotes)

        # æ ¼å¼åŒ–é‡‘å¥å¼•ç”¨
        quotes_text = ""
        if key_quotes:
            quotes_text = "\n".join([
                f"â€¢ {quote[:100]}..." if len(quote) > 100 else f"â€¢ {quote}"
                for quote in key_quotes[:3]
            ])

        system_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å°çº¢ä¹¦è¥é”€æ–‡æ¡ˆä¸“å®¶ã€‚
è¯·æ ¹æ®æ’­å®¢å®Œæ•´å­—å¹•å†…å®¹ï¼Œç”Ÿæˆ 3 ä¸ªä¸åŒè§’åº¦çš„è¥é”€æ–‡æ¡ˆç‰ˆæœ¬ã€‚

ã€æ ¸å¿ƒåŸåˆ™ã€‘æ¯ä¸ªè§’åº¦éƒ½å¿…é¡»åŸºäºå®Œæ•´çš„å­—å¹•å†…å®¹ï¼Œè€Œä¸æ˜¯æŒ‰ç« èŠ‚æ‹†åˆ†

ã€é‡è¦çº¦æŸã€‘
1. å¿…é¡»ä¸¥æ ¼åŸºäºå­—å¹•å†…å®¹ç”Ÿæˆï¼Œä¸å¾—ç¼–é€ å­—å¹•ä¸­æ²¡æœ‰çš„ä¿¡æ¯
2. åªèƒ½æç‚¼ã€é‡ç»„ã€æ¶¦è‰²å­—å¹•ä¸­çš„å†…å®¹
3. æ¯ä¸ªè§’åº¦éƒ½ä»å®Œæ•´å†…å®¹å‡ºå‘ï¼Œé€‰æ‹©ä¸åŒçš„åˆ‡å…¥ç‚¹
4. æ‰€æœ‰æ•°æ®ã€æ¡ˆä¾‹ã€è§‚ç‚¹å¿…é¡»æ¥è‡ªå­—å¹•åŸæ–‡

ã€æ­£ç¡®çš„è§’åº¦ç¤ºä¾‹ã€‘
å¦‚æœå†…å®¹åŒ…å«æ³•å¾‹ã€å†™ä½œã€å¿ƒç†ä¸‰ä¸ªæ–¹é¢ï¼Œåˆ™ä¸‰ä¸ªè§’åº¦å¯ä»¥æ˜¯ï¼š
  * è§’åº¦1ï¼ˆäº§å“å‘ï¼‰ï¼šäº§å“ç»ç†æ˜¯æ€ä¹ˆæ€è€ƒçš„
  * è§’åº¦2ï¼ˆä¸ªäººå­¦ä¹ å‘ï¼‰ï¼šæ€ä¹ˆç”¨AIè¶Šç‹±
  * è§’åº¦3ï¼ˆèŒåœºå‘/å•†ä¸šå‘ï¼‰ï¼šæ€ä¹ˆæ‹“å±•ç¬¬äºŒäº§å“

ã€ä»»åŠ¡ã€‘
åˆ†æå­—å¹•å†…å®¹ï¼Œå®šä¹‰ 3 ä¸ªä¸åŒçš„å†…å®¹è§’åº¦ï¼Œä¸ºæ¯ä¸ªè§’åº¦ç”Ÿæˆï¼š
1. angle_name: è§’åº¦åç§°ï¼ˆ4-8å­—ï¼Œç®€æ´æ˜äº†ï¼‰
2. title: æ ‡é¢˜ï¼ˆåŒ…å«emojiï¼Œ30å­—ä»¥å†…ï¼‰
3. content: æ­£æ–‡å†…å®¹ï¼ˆ300-500å­—ï¼‰
4. hashtags: æ ‡ç­¾åˆ—è¡¨ï¼ˆ5ä¸ªï¼Œä»¥#å¼€å¤´ï¼‰

ã€æ­£æ–‡è¦æ±‚ã€‘
- å¼€å¤´ç®€æ´æœ‰åŠ›ï¼Œç›´æ¥ç‚¹é¢˜
- ä½¿ç”¨é€‚é‡ emoji è¡¨æƒ…ç‚¹ç¼€
- å†…å®¹åˆ†æ®µæ¸…æ™°ï¼Œä½¿ç”¨é¡¹ç›®ç¬¦å·
- çªå‡º"å¹²è´§"å’Œ"ä»·å€¼"
- ç»“å°¾è¦æœ‰ CTAï¼ˆç‚¹èµæ”¶è—å…³æ³¨ï¼‰

ã€è¾“å‡ºæ ¼å¼ã€‘
å¿…é¡»è¿”å›æœ‰æ•ˆçš„ JSON æ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹ç»“æ„ï¼š
{
  "angles": [
    {
      "angle_name": "äº§å“æ€ç»´",
      "title": "ğŸ¯ äº§å“ç»ç†çš„æ€è€ƒæ–¹å¼",
      "content": "æ­£æ–‡å†…å®¹...",
      "hashtags": ["#äº§å“æ€ç»´", "#èŒåœºå¹²è´§", ...]
    },
    ...
  ]
}"""

        # DEBUG: éªŒè¯å­—å¹•å†…å®¹æ˜¯å¦å®Œæ•´ä¼ é€’
        logger.info(
            f"Episode {episode.id} å­—å¹•ç»Ÿè®¡: "
            f"æ€»è¡Œæ•°={len(transcripts_text.split(chr(10)))}, "
            f"æ€»å­—ç¬¦æ•°={len(transcripts_text)}"
        )

        user_prompt = f"""æ’­å®¢æ ‡é¢˜ï¼š{episode.title}
æ’­å®¢æ‘˜è¦ï¼š{episode.ai_summary or 'æš‚æ— æ‘˜è¦'}

æ ¸å¿ƒé‡‘å¥ï¼š
{quotes_text if quotes_text else 'æš‚æ— '}

å®Œæ•´å­—å¹•å†…å®¹ï¼š
{transcripts_text}

è¯·æ ¹æ®ä»¥ä¸Šå®Œæ•´å­—å¹•å†…å®¹ç”Ÿæˆ 3 ä¸ªä¸åŒè§’åº¦çš„è¥é”€æ–‡æ¡ˆ JSONï¼š"""

        logger.info(
            f"å‘é€ç»™ LLM çš„ prompt æ€»é•¿åº¦: "
            f"{len(system_prompt) + len(user_prompt)} å­—ç¬¦"
        )

        try:
            # è·å–æ”¯æŒç»“æ„åŒ–è¾“å‡ºçš„ LLM
            structured_llm = self.structured_llm.with_structured_output(
                schema=MultiAngleMarketingResponse
            )

            # è°ƒç”¨ AI - éªŒè¯å¤±è´¥ä¼šæŠ›å‡º ValueErrorï¼Œè§¦å‘ @ai_retry
            result: MultiAngleMarketingResponse = structured_llm.invoke([
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ])

            # è½¬æ¢ä¸º MarketingCopy åˆ—è¡¨
            return self._convert_structured_response_to_marketing_copy(
                result, episode.id
            )

        except Exception as e:
            logger.error(f"AI è°ƒç”¨å¤±è´¥: {e}ï¼Œç›´æ¥ä½¿ç”¨æ‘˜è¦å…œåº•")
            # âœ… ç›´æ¥ä½¿ç”¨æ‘˜è¦å…œåº•ï¼Œä¸åšéƒ¨åˆ†è§£æ
            return self._generate_fallback_multi_angle_copy(episode, key_quotes)

    def _convert_structured_response_to_marketing_copy(
        self,
        response: MultiAngleMarketingResponse,
        episode_id: int
    ) -> List[MarketingCopy]:
        """
        å°†ç»“æ„åŒ–å“åº”è½¬æ¢ä¸º MarketingCopy åˆ—è¡¨

        Args:
            response: MultiAngleMarketingResponse å¯¹è±¡ï¼ˆå·²é€šè¿‡ Pydantic éªŒè¯ï¼‰
            episode_id: Episode ID

        Returns:
            List[MarketingCopy]: 3ä¸ªä¸åŒè§’åº¦çš„æ–‡æ¡ˆå¯¹è±¡
        """
        angle_copies = []

        for angle in response.angles:
            angle_copies.append(MarketingCopy(
                title=angle.title,
                content=angle.content,
                hashtags=angle.hashtags,
                key_quotes=[],
                metadata={
                    "episode_id": episode_id,
                    "platform": "xiaohongshu",
                    "angle_tag": angle.angle_name
                }
            ))

        logger.info(
            f"æˆåŠŸè½¬æ¢ {len(angle_copies)} ä¸ªç»“æ„åŒ–è§’åº¦æ–‡æ¡ˆ: "
            f"{[a.angle_name for a in response.angles]}"
        )

        return angle_copies

    def _generate_fallback_multi_angle_copy(
        self,
        episode: Episode,
        key_quotes: List[str]
    ) -> List[MarketingCopy]:
        """
        ç”Ÿæˆå¤‡ç”¨å¤šè§’åº¦æ–‡æ¡ˆï¼ˆå½“ LLM è°ƒç”¨å¤±è´¥æ—¶ï¼‰

        âœ… ä½¿ç”¨ episode.ai_summary ä½œä¸ºå…œåº•å†…å®¹

        Args:
            episode: Episode å¯¹è±¡
            key_quotes: é‡‘å¥åˆ—è¡¨

        Returns:
            List[MarketingCopy]: å•ä¸ªå¤‡ç”¨æ–‡æ¡ˆå¯¹è±¡ï¼ˆåŸºäºæ‘˜è¦ï¼‰
        """
        # ä½¿ç”¨ episode.ai_summary æˆ– episode.title ä½œä¸ºå†…å®¹
        content = episode.ai_summary or episode.title

        # é™åˆ¶æ ‡é¢˜é•¿åº¦
        title = episode.title[:30] if len(episode.title) > 30 else episode.title

        fallback_copy = MarketingCopy(
            title=title,
            content=content,
            hashtags=["#æ’­å®¢", "#å­¦ä¹ ", "#è‹±è¯­"],
            key_quotes=key_quotes,
            metadata={
                "episode_id": episode.id,
                "platform": "xiaohongshu",
                "angle_tag": "é»˜è®¤",
                "fallback": True
            }
        )

        return [fallback_copy]

    def _call_llm_for_xiaohongshu_content(
        self,
        episode: Episode,
        key_quotes: List[str]
    ) -> str:
        """
        è°ƒç”¨ LLM ç”Ÿæˆå°çº¢ä¹¦é£æ ¼æ­£æ–‡

        Args:
            episode: Episode å¯¹è±¡
            key_quotes: é‡‘å¥åˆ—è¡¨

        Returns:
            str: å°çº¢ä¹¦é£æ ¼æ­£æ–‡
        """
        # è·å–å®Œæ•´çš„å­—å¹•å†…å®¹ï¼ˆè‹±æ–‡+ä¸­æ–‡ç¿»è¯‘ï¼‰
        transcripts_text = self._get_full_transcripts(episode.id)

        if self._openai_client:
            try:
                # æ ¼å¼åŒ–é‡‘å¥å¼•ç”¨
                quotes_text = ""
                if key_quotes:
                    quotes_text = "\n".join([
                        f"â€¢ {quote[:100]}..." if len(quote) > 100 else f"â€¢ {quote}"
                        for quote in key_quotes[:3]
                    ])

                system_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å°çº¢ä¹¦è¥é”€æ–‡æ¡ˆä¸“å®¶ã€‚
è¯·æ ¹æ®æ’­å®¢å®Œæ•´å­—å¹•å†…å®¹ç”Ÿæˆå°çº¢ä¹¦é£æ ¼çš„æ–‡ç« æ­£æ–‡ã€‚

è¦æ±‚ï¼š
1. å¼€å¤´ç®€æ´æœ‰åŠ›ï¼Œç›´æ¥ç‚¹é¢˜ï¼Œè¥é€ å…±é¸£
2. ä½¿ç”¨é€‚é‡ emoji è¡¨æƒ…ç‚¹ç¼€ï¼ˆâœ…ã€ğŸ’¡ã€ğŸ”¥ã€âœ¨ç­‰ï¼‰ï¼Œä¸è¦è¿‡åº¦
3. å†…å®¹åˆ†æ®µæ¸…æ™°ï¼Œä½¿ç”¨é¡¹ç›®ç¬¦å·
4. çªå‡º"å¹²è´§"å’Œ"ä»·å€¼"
5. ç»“å°¾è¦æœ‰ CTAï¼ˆç‚¹èµæ”¶è—å…³æ³¨ï¼‰
6. å­—æ•°æ§åˆ¶åœ¨ 300-500 å­—
7. ä¸è¦ä½¿ç”¨ Markdown æ ¼å¼ï¼ˆä¸è¦æœ‰ ## æ ‡é¢˜ç­‰ï¼‰
8. **å¿…é¡»åŸºäºå®Œæ•´çš„å­—å¹•å†…å®¹ç”Ÿæˆï¼Œä¸å¾—åç¦»åŸæ„**

é£æ ¼å‚è€ƒï¼š
åˆ†äº«ä¸€ä¸ªæå‡è‹±è¯­å­¦ä¹ æ•ˆç‡çš„æ–¹æ³•ï¼Œäº²æµ‹æœ‰æ•ˆï¼

âœ… æ ¸å¿ƒè§‚ç‚¹1
è¯¦ç»†è¯´æ˜...

âœ… æ ¸å¿ƒè§‚ç‚¹2
è¯¦ç»†è¯´æ˜...

ğŸ’¡ é‡ç‚¹æç¤º
é‡‘å¥å¼•ç”¨...

å»ºè®®æ”¶è—èµ·æ¥æ…¢æ…¢çœ‹ï¼Œæœ‰é—®é¢˜è¯„è®ºåŒºè§ï¼

ç‚¹èµæ”¶è—å…³æ³¨ï¼Œåˆ†äº«æ›´å¤šå®ç”¨å†…å®¹ï¼"""

                user_prompt = f"""æ’­å®¢æ ‡é¢˜ï¼š{episode.title}
æ’­å®¢æ‘˜è¦ï¼š{episode.ai_summary or 'æš‚æ— æ‘˜è¦'}

æ ¸å¿ƒé‡‘å¥ï¼š
{quotes_text if quotes_text else 'æš‚æ— '}

å®Œæ•´å­—å¹•å†…å®¹ï¼š
{transcripts_text}

è¯·æ ¹æ®ä»¥ä¸Šå®Œæ•´å­—å¹•å†…å®¹ç”Ÿæˆå°çº¢ä¹¦é£æ ¼çš„æ–‡ç« æ­£æ–‡ï¼š"""

                executor = ThreadPoolExecutor(max_workers=1)

                def call_ai():
                    completion = self._openai_client.chat.completions.create(
                        model=self._llm_config["model"],
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        temperature=0.8,
                    )
                    return completion.choices[0].message.content

                try:
                    future = executor.submit(call_ai)
                    response_text = future.result(timeout=AI_QUERY_TIMEOUT)
                    executor.shutdown(wait=False)
                    return response_text.strip()

                except FutureTimeoutError:
                    logger.error("AI å†…å®¹ç”Ÿæˆè¶…æ—¶ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
                    executor.shutdown(wait=False)
                except Exception as e:
                    logger.error(f"AI å†…å®¹ç”Ÿæˆå¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")

            except Exception as e:
                logger.error(f"AI å†…å®¹ç”Ÿæˆåˆå§‹åŒ–å¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")

        # å¤‡ç”¨æ–¹æ¡ˆï¼šè¿”å›æ¨¡æ‹Ÿæ•°æ®
        content = f"""åˆ†äº«ä¸€ä¸ªæå‡è‹±è¯­å­¦ä¹ æ•ˆç‡çš„æ–¹æ³•ï¼Œäº²æµ‹æœ‰æ•ˆï¼

å…³äº {episode.title}ï¼Œæœ‰ä¸€äº›å®ç”¨çš„å¿ƒå¾—æƒ³å’Œå¤§å®¶åˆ†äº«...

âœ… æ ¸å¿ƒè§‚ç‚¹1
è¿™ä¸ªè¯é¢˜çœŸçš„å¾ˆæœ‰æ„æ€ï¼Œè®©æˆ‘æ·±æ€äº†å¾ˆä¹…ã€‚

âœ… æ ¸å¿ƒè§‚ç‚¹2
ç‰¹åˆ«æ˜¯åœ¨å®é™…åº”ç”¨ä¸­ï¼Œä½ ä¼šå‘ç°å¾ˆå¤šç»†èŠ‚å€¼å¾—æ³¨æ„ã€‚

ğŸ’¡ é‡ç‚¹æç¤º
{key_quotes[0] if key_quotes else 'è®°å¾—å¤šæ€è€ƒï¼Œå¤šå®è·µï¼'}

å»ºè®®æ”¶è—èµ·æ¥æ…¢æ…¢çœ‹ï¼Œæœ‰é—®é¢˜è¯„è®ºåŒºè§ï¼

ç‚¹èµæ”¶è—å…³æ³¨ï¼Œåˆ†äº«æ›´å¤šå®ç”¨å†…å®¹ï¼"""

        return content

    # ========================================================================
    # æ–‡æ¡ˆæŒä¹…åŒ–
    # ========================================================================

    def save_marketing_copy(
        self,
        episode_id: int,
        copy: MarketingCopy,
        platform: str = "xhs",
        angle_tag: str = "default"
    ) -> MarketingPost:
        """
        ä¿å­˜è¥é”€æ–‡æ¡ˆåˆ°æ•°æ®åº“

        Args:
            episode_id: Episode ID
            copy: è¥é”€æ–‡æ¡ˆå¯¹è±¡
            platform: å¹³å°æ ‡è¯†
            angle_tag: ç­–ç•¥æ ‡ç­¾

        Returns:
            MarketingPost: åˆ›å»ºçš„æ•°æ®åº“è®°å½•
        """
        logger.info(f"ä¿å­˜è¥é”€æ–‡æ¡ˆ: episode_id={episode_id}, platform={platform}")

        post = MarketingPost(
            episode_id=episode_id,
            platform=platform,
            angle_tag=angle_tag,
            title=copy.title,
            content=copy.content,
            status="pending"
        )

        self.db.add(post)
        self.db.flush()

        logger.info(f"è¥é”€æ–‡æ¡ˆå·²ä¿å­˜: id={post.id}")
        return post

    def load_marketing_copy(self, post_id: int) -> Optional[MarketingPost]:
        """
        ä»æ•°æ®åº“åŠ è½½è¥é”€æ–‡æ¡ˆ

        Args:
            post_id: æ–‡æ¡ˆ ID

        Returns:
            Optional[MarketingPost]: æ–‡æ¡ˆå¯¹è±¡ï¼Œä¸å­˜åœ¨è¿”å› None
        """
        return self.db.query(MarketingPost).filter(MarketingPost.id == post_id).first()
